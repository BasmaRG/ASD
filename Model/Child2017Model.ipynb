{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Child2017Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "91X8_FdEOgzo"
      },
      "source": [
        "import time\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Data/Child-Data2017.csv', na_values='?')\n",
        "data.rename(columns={'Class/ASD': 'class'}, inplace=True)\n",
        "\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == type(object):\n",
        "        le = LabelEncoder()\n",
        "        data[column] = le.fit_transform(data[column].astype(str))\n",
        "\n",
        "names = []\n",
        "models = []\n",
        "\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('SVM', SVC()))\n",
        "models.append(('AB', AdaBoostClassifier()))\n",
        "models.append(('GBM', GradientBoostingClassifier()))\n",
        "models.append(('RF', RandomForestClassifier()))\n",
        "models.append(('ET', ExtraTreesClassifier()))\n",
        "\n",
        "X=data[['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score',\n",
        "       'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']]\n",
        "Y=data['class']\n",
        "\n",
        "start_time = 0\n",
        "elapsed_time = 0\n",
        "confusion=0\n",
        "pred=0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw8Vi5poO7an"
      },
      "source": [
        "# Crossvalidation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNYKqUgiOvTI",
        "outputId": "69607d2a-06b6-4525-a53c-4d5d3ff6264d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seed = 7\n",
        "kfold = KFold(n_splits=10, random_state=seed)\n",
        "for name, m in models:\n",
        "    start_time = time.time()\n",
        "    pred = cross_val_predict(m, X,Y, cv=kfold )\n",
        "    elapsed_time = time.time() - start_time   \n",
        "    confusion = metrics.confusion_matrix(Y,pred)\n",
        "    #[row, column]\n",
        "    TP = confusion[1, 1]\n",
        "    TN = confusion[0, 0]\n",
        "    FP = confusion[0, 1]\n",
        "    FN = confusion[1, 0]\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    specificity = TN / (TN + FP)\n",
        "    sensitivity = TP / float(FN + TP)\n",
        "    error = (FP + FN) / float(TP + TN + FP + FN) # equal #error_rate = 1 - accuracy\n",
        "    F1Score = f1_score(Y, pred, average='binary')\n",
        "    AUC=metrics.roc_auc_score(Y, pred)\n",
        "    print(name)\n",
        "    print('%.4f' % elapsed_time)\n",
        "    print('%.4f' % float(accuracy *100.0))\n",
        "    print('%.4f' %float(specificity*100.0))\n",
        "    print('%.4f' %float(sensitivity*100.0))\n",
        "    print('%.4f' %float(AUC*100.0))\n",
        "    print('%.4f' %float(F1Score*100.0))\n",
        "    print('%.4f' %float(error*100.0))\n",
        "    print(' =======================')      \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LR\n",
            "0.0711\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "0.0000\n",
            " =======================\n",
            "LDA\n",
            "0.0503\n",
            "96.9178\n",
            "94.0397\n",
            "100.0000\n",
            "97.0199\n",
            "96.9072\n",
            "3.0822\n",
            " =======================\n",
            "CART\n",
            "0.0240\n",
            "93.8356\n",
            "92.0530\n",
            "95.7447\n",
            "93.8988\n",
            "93.7500\n",
            "6.1644\n",
            " =======================\n",
            "NB\n",
            "0.0265\n",
            "88.6986\n",
            "94.0397\n",
            "82.9787\n",
            "88.5092\n",
            "87.6404\n",
            "11.3014\n",
            " =======================\n",
            "KNN\n",
            "0.0446\n",
            "91.7808\n",
            "88.0795\n",
            "95.7447\n",
            "91.9121\n",
            "91.8367\n",
            "8.2192\n",
            " =======================\n",
            "SVM\n",
            "0.0376\n",
            "98.2877\n",
            "99.3377\n",
            "97.1631\n",
            "98.2504\n",
            "98.2079\n",
            "1.7123\n",
            " =======================\n",
            "AB\n",
            "0.7105\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "0.0000\n",
            " =======================\n",
            "GBM\n",
            "0.6178\n",
            "93.4932\n",
            "92.7152\n",
            "94.3262\n",
            "93.5207\n",
            "93.3333\n",
            "6.5068\n",
            " =======================\n",
            "RF\n",
            "1.3076\n",
            "94.1781\n",
            "93.3775\n",
            "95.0355\n",
            "94.2065\n",
            "94.0351\n",
            "5.8219\n",
            " =======================\n",
            "ET\n",
            "0.9901\n",
            "94.5205\n",
            "94.7020\n",
            "94.3262\n",
            "94.5141\n",
            "94.3262\n",
            "5.4795\n",
            " =======================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud_BOSj8PABe"
      },
      "source": [
        "# leave"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te5kUT61Ovgu",
        "outputId": "8223d20b-755e-4ed4-c88a-021573ca8a1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "num_folds = 10\n",
        "for name, m in models: \n",
        "    loocv = LeaveOneOut() \n",
        "    start_time=time.time()\n",
        "    pred = cross_val_predict(m, X,Y, cv=loocv )\n",
        "    elapsed_time = time.time() - start_time\n",
        "    confusion = metrics.confusion_matrix(Y,pred)\n",
        "    #[row, column]\n",
        "    TP = confusion[1, 1]\n",
        "    TN = confusion[0, 0]\n",
        "    FP = confusion[0, 1]\n",
        "    FN = confusion[1, 0]\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    specificity = TN / (TN + FP)\n",
        "    sensitivity = TP / float(FN + TP)\n",
        "    F1Score = f1_score(Y, pred, average='binary')\n",
        "    AUC=metrics.roc_auc_score(Y, pred)\n",
        "    error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "    print(name)\n",
        "    print('%.4f' % elapsed_time)\n",
        "    print('%.4f' % float(accuracy *100.0))\n",
        "    print('%.4f' %float(specificity*100.0))\n",
        "    print('%.4f' %float(sensitivity*100.0))\n",
        "    print('%.4f' %float(AUC*100.0))\n",
        "    print('%.4f' %float(F1Score*100.0))\n",
        "    print('%.4f' %float(error*100.0))\n",
        "    print(' =======================') \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR\n",
            "1.7298\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "0.0000\n",
            " =======================\n",
            "LDA\n",
            "0.8197\n",
            "97.2603\n",
            "94.7020\n",
            "100.0000\n",
            "97.3510\n",
            "97.2414\n",
            "2.7397\n",
            " =======================\n",
            "CART\n",
            "0.6599\n",
            "93.1507\n",
            "91.3907\n",
            "95.0355\n",
            "93.2131\n",
            "93.0556\n",
            "6.8493\n",
            " =======================\n",
            "NB\n",
            "0.6753\n",
            "90.4110\n",
            "95.3642\n",
            "85.1064\n",
            "90.2353\n",
            "89.5522\n",
            "9.5890\n",
            " =======================\n",
            "KNN\n",
            "0.8332\n",
            "93.4932\n",
            "90.7285\n",
            "96.4539\n",
            "93.5912\n",
            "93.4708\n",
            "6.5068\n",
            " =======================\n",
            "SVM\n",
            "1.1428\n",
            "97.9452\n",
            "98.6755\n",
            "97.1631\n",
            "97.9193\n",
            "97.8571\n",
            "2.0548\n",
            " =======================\n",
            "AB\n",
            "20.2333\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "0.0000\n",
            " =======================\n",
            "GBM\n",
            "17.7480\n",
            "94.8630\n",
            "94.0397\n",
            "95.7447\n",
            "94.8922\n",
            "94.7368\n",
            "5.1370\n",
            " =======================\n",
            "RF\n",
            "38.0344\n",
            "93.8356\n",
            "93.3775\n",
            "94.3262\n",
            "93.8519\n",
            "93.6620\n",
            "6.1644\n",
            " =======================\n",
            "ET\n",
            "28.7177\n",
            "93.8356\n",
            "93.3775\n",
            "94.3262\n",
            "93.8519\n",
            "93.6620\n",
            "6.1644\n",
            " =======================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nVWf_yBPC7n"
      },
      "source": [
        "# train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjOWbeN-OvIC",
        "outputId": "1f69c3a9-2a36-4a6c-e2d2-5c1199d9e4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_size = 0.3\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "for name, m in models:\n",
        "    model = m\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, Y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    confusion = metrics.confusion_matrix(Y_test,pred)\n",
        "    #[row, column]\n",
        "    TP = confusion[1, 1]\n",
        "    TN = confusion[0, 0]\n",
        "    FP = confusion[0, 1]\n",
        "    FN = confusion[1, 0]\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    specificity = TN / (TN + FP)\n",
        "    sensitivity = TP / float(FN + TP)\n",
        "    F1Score = f1_score(Y_test, pred, average='binary')\n",
        "    AUC=metrics.roc_auc_score(Y_test, pred)\n",
        "    class_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "    print(name)\n",
        "    print('%.4f' % elapsed_time)\n",
        "    print('%.4f' % float(accuracy *100.0))\n",
        "    print('%.4f' %float(specificity*100.0))\n",
        "    print('%.4f' %float(sensitivity*100.0))\n",
        "    print('%.4f' %float(AUC*100.0))\n",
        "    print('%.4f' %float(F1Score*100.0))\n",
        "    print('%.4f' %float(class_error*100.0))\n",
        "    print(' ====')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR\n",
            "0.0108\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "0.0000\n",
            " ====\n",
            "LDA\n",
            "0.0038\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "0.0000\n",
            " ====\n",
            "CART\n",
            "0.0021\n",
            "87.5000\n",
            "83.3333\n",
            "92.5000\n",
            "87.9167\n",
            "87.0588\n",
            "12.5000\n",
            " ====\n",
            "NB\n",
            "0.0029\n",
            "88.6364\n",
            "85.4167\n",
            "92.5000\n",
            "88.9583\n",
            "88.0952\n",
            "11.3636\n",
            " ====\n",
            "KNN\n",
            "0.0053\n",
            "90.9091\n",
            "83.3333\n",
            "100.0000\n",
            "91.6667\n",
            "90.9091\n",
            "9.0909\n",
            " ====\n",
            "SVM\n",
            "0.0034\n",
            "94.3182\n",
            "91.6667\n",
            "97.5000\n",
            "94.5833\n",
            "93.9759\n",
            "5.6818\n",
            " ====\n",
            "AB\n",
            "0.0786\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "100.0000\n",
            "0.0000\n",
            " ====\n",
            "GBM\n",
            "0.0635\n",
            "93.1818\n",
            "87.5000\n",
            "100.0000\n",
            "93.7500\n",
            "93.0233\n",
            "6.8182\n",
            " ====\n",
            "RF\n",
            "0.1380\n",
            "92.0455\n",
            "89.5833\n",
            "95.0000\n",
            "92.2917\n",
            "91.5663\n",
            "7.9545\n",
            " ====\n",
            "ET\n",
            "0.1034\n",
            "90.9091\n",
            "89.5833\n",
            "92.5000\n",
            "91.0417\n",
            "90.2439\n",
            "9.0909\n",
            " ====\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}